{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wXSyy7GMCQ3"
      },
      "source": [
        "# Calculating the **Relevancy Score**, **Profile Score**, and **Matching Score** for DRDO experts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLgWmkFKMCQ8"
      },
      "source": [
        "## Load the Required Libraries and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR0MXM0XMCQ9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the CSV files\n",
        "experts_df = pd.read_csv('experts.csv')\n",
        "interview_subjects_df, interview_subjects_dfx = pd.read_csv('interview_subjects.csv'),pd.read_csv('interview_subjects.csv')\n",
        "candidates_df = pd.read_csv('candidates.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qya2oM8MCRA"
      },
      "source": [
        "## Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4hDItfdMCRB"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    label_encoders = {}\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype == 'object':\n",
        "            le = LabelEncoder()\n",
        "            df[column] = le.fit_transform(df[column].astype(str))\n",
        "            label_encoders[column] = le\n",
        "    return df, label_encoders\n",
        "\n",
        "# Preprocess all dataframes\n",
        "experts_df, experts_encoders = preprocess_data(experts_df)\n",
        "interview_subjects_df, interview_subjects_encoders = preprocess_data(interview_subjects_df)\n",
        "candidates_df, candidates_encoders = preprocess_data(candidates_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEvGx75gMCRC"
      },
      "source": [
        "## Calculate Relevancy Score Between Experts and Interview Subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBIrtQSDMCRD"
      },
      "outputs": [],
      "source": [
        "# Map interview subject features to corresponding expert features\n",
        "feature_mapping = {\n",
        "    'Interview_Subfields_Specializations': 'Expert_Field_of_Study',\n",
        "    'Interview_Required_Technical_Skills': 'Expert_Technical_Skills',\n",
        "    'Interview_Specific_Technologies': 'Expert_Relevant_Technology',\n",
        "    'Interview_Core_Concepts': 'Expert_Technical_Skills',  # Assuming a match\n",
        "    'Interview_Level_of_Expertise': 'Expert_Industry_Experience'\n",
        "}\n",
        "\n",
        "# Extract the relevant columns\n",
        "experts_mapped_df = experts_df[feature_mapping.values()]\n",
        "interview_subjects_mapped_df = interview_subjects_df[feature_mapping.keys()]\n",
        "\n",
        "# Rename columns in interview_subjects_mapped_df to match experts_mapped_df\n",
        "interview_subjects_mapped_df.columns = experts_mapped_df.columns\n",
        "\n",
        "# Combine experts and interview subjects for scaling\n",
        "combined_df = pd.concat([experts_mapped_df, interview_subjects_mapped_df], axis=0)\n",
        "\n",
        "# Standardize the combined data\n",
        "scaler = StandardScaler()\n",
        "combined_scaled = scaler.fit_transform(combined_df)\n",
        "\n",
        "# Split the scaled data back into experts and interview subjects\n",
        "experts_scaled = combined_scaled[:len(experts_mapped_df)]\n",
        "interview_subjects_scaled = combined_scaled[len(experts_mapped_df):]\n",
        "\n",
        "# Calculate Relevancy Score\n",
        "relevancy_scores = cosine_similarity(experts_scaled, interview_subjects_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UwafTLuMCRF"
      },
      "source": [
        "## Calculate Profile Score Between Experts and Candidates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Iz7rGhdMCRG"
      },
      "outputs": [],
      "source": [
        "# Map candidate features to corresponding expert features\n",
        "candidate_feature_mapping = {\n",
        "    'Candidate_Field_of_Study': 'Expert_Field_of_Study',\n",
        "    'Candidate_Technical_Skills': 'Expert_Technical_Skills',\n",
        "    'Candidate_Industry_Experience': 'Expert_Industry_Experience',\n",
        "    'Candidate_Certifications': 'Expert_Certifications'\n",
        "}\n",
        "\n",
        "# Extract the relevant columns\n",
        "experts_mapped_for_candidates_df = experts_df[candidate_feature_mapping.values()]\n",
        "candidates_mapped_df = candidates_df[candidate_feature_mapping.keys()]\n",
        "\n",
        "# Rename columns in candidates_mapped_df to match experts_mapped_for_candidates_df\n",
        "candidates_mapped_df.columns = experts_mapped_for_candidates_df.columns\n",
        "\n",
        "# Combine experts and candidates for scaling\n",
        "combined_candidates_df = pd.concat([experts_mapped_for_candidates_df, candidates_mapped_df], axis=0)\n",
        "\n",
        "# Standardize the combined data\n",
        "scaler_candidates = StandardScaler()\n",
        "combined_candidates_scaled = scaler_candidates.fit_transform(combined_candidates_df)\n",
        "\n",
        "# Split the scaled data back into experts and candidates\n",
        "experts_scaled_for_candidates = combined_candidates_scaled[:len(experts_mapped_for_candidates_df)]\n",
        "candidates_scaled = combined_candidates_scaled[len(experts_mapped_for_candidates_df):]\n",
        "\n",
        "\n",
        "# Calculate Profile Score\n",
        "profile_scores = cosine_similarity(experts_scaled_for_candidates, candidates_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZohsgDOtMCRH"
      },
      "source": [
        "## Calculate the Matching Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhav7jpSMCRH"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty list to store matching scores\n",
        "matching_scores_list = []\n",
        "\n",
        "# Loop over interview subjects to calculate matching scores for each\n",
        "for i in range(interview_subjects_df.shape[0]):\n",
        "    # Relevancy score for the current interview subject\n",
        "    relevancy_score = relevancy_scores[:, i].reshape(-1, 1)\n",
        "\n",
        "    # Calculate Matching Score for each expert-candidate pair\n",
        "    matching_score = (relevancy_score + profile_scores) / 2\n",
        "\n",
        "    # Store the result in the list\n",
        "    matching_scores_list.append(matching_score)\n",
        "\n",
        "# Combine all matching scores into a single matrix (experts, candidates, interview subjects)\n",
        "matching_scores_combined = np.stack(matching_scores_list, axis=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVUWZq8sVjQ5"
      },
      "source": [
        "## Filter and Save Results to an Excel File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0PDf_ZSMCRI"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty list to store rows\n",
        "rows = []\n",
        "\n",
        "# Loop through all indices to extract relevant data\n",
        "for expert_idx in range(matching_scores_combined.shape[0]):\n",
        "    for candidate_idx in range(matching_scores_combined.shape[1]):\n",
        "        for subject_idx in range(matching_scores_combined.shape[2]):\n",
        "            score = matching_scores_combined[expert_idx,\n",
        "                                             candidate_idx, subject_idx]\n",
        "            if score >= 0.7:  # Only include scores above 70%\n",
        "                rows.append({\n",
        "                    'SNo': len(rows) + 1,\n",
        "                    'Expert_ID': experts_df.iloc[expert_idx]['Expert_ID'],\n",
        "                    # Assuming 'Candidate_Name' is unique\n",
        "                    'Candidate_ID': candidates_df.iloc[candidate_idx]['Candidate_ID'],\n",
        "                    'Interview_Subject_Job_Role': interview_subjects_dfx.iloc[subject_idx]['Interview_Job_Role'],\n",
        "                    'Matching_Score': score*100\n",
        "                })\n",
        "\n",
        "# Convert the list of rows into a DataFrame\n",
        "matching_scores_df = pd.DataFrame(rows)\n",
        "\n",
        "# Sort the DataFrame by Matching_Score in descending order\n",
        "matching_scores_df = matching_scores_df.sort_values(\n",
        "    by='Matching_Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "matching_scores_df.to_excel('matching_scores.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prieview of the Final Score Table "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "gVjPAhDJMCRI",
        "outputId": "2aca73a3-9479-49a1-c0c5-99a1993385a5"
      },
      "outputs": [],
      "source": [
        "display(matching_scores_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
